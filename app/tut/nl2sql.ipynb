{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sqlite3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "from pyprojroot import here # IMP\n",
    "db_path = str(here(\"data\")) + \"/student.db\"\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CREATE TABLE \"STUDENT\" (\n",
      "\t\"NAME\" VARCHAR(25), \n",
      "\t\"CLASS\" VARCHAR(25), \n",
      "\t\"SECTION\" VARCHAR(25), \n",
      "\t\"MARKS\" INTEGER\n",
      ")\n",
      "\n",
      "/*\n",
      "3 rows from STUDENT table:\n",
      "NAME\tCLASS\tSECTION\tMARKS\n",
      "Krish\tData Science\tA\t90\n",
      "Salman\tCS\tB\t60\n",
      "Sunny\tData Science\tD\t70\n",
      "*/\n"
     ]
    }
   ],
   "source": [
    "print(db.get_table_info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method SQLDatabase.get_usable_table_names of <langchain_community.utilities.sql_database.SQLDatabase object at 0x000001A69C74E350>>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.get_usable_table_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_groq import ChatGroq\n",
    "os.environ['GROQ_API_KEY'] = os.getenv('GROQ_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGroq(model=\"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! ðŸ‘‹  How can I help you today? ðŸ˜Š \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 11, 'total_tokens': 27, 'completion_time': 0.029090909, 'prompt_time': 0.00017858, 'queue_time': 0.013972987000000001, 'total_time': 0.029269489}, 'model_name': 'gemma2-9b-it', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-47351176-ce5f-415e-ba7c-c96ea6dc5094-0', usage_metadata={'input_tokens': 11, 'output_tokens': 16, 'total_tokens': 27})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hellow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NO use as static prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First Test\n",
    "sql_chain = create_sql_query_chain(llm,db)\n",
    "\n",
    "sql_cmd = sql_chain.invoke({\"question\":\"Tell me number of students from class data science\"})\n",
    "print(sql_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TO run command on SQL DB\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "exe_query = QuerySQLDataBaseTool(db=db)\n",
    "# exe_query.invoke(sql_cmd)\n",
    "# checker.invoke(sql_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = sql_chain|exe_query\n",
    "chain.invoke({\"question\":\"Tell me number of students from class data science\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default Prompt\n",
    "print(chain.get_prompts()[0].template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customize Prompt for output\n",
    "\n",
    "from operator import itemgetter\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Given the following user question, corresponding sql query, and SQL result. Answer from user point of view and avoid mention of SQL query\n",
    "If you don't find the answer ask user to repharse question.\n",
    "Question:{question}\n",
    "SQL_query:{query}\n",
    "SQL_Result:{result}\n",
    "Answer:\n",
    "\"\"\")\n",
    "                                            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rephrase_answer = answer_prompt | llm |StrOutputParser()\n",
    "\n",
    "final_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_chain).assign(\n",
    "        result = itemgetter(\"query\") | exe_query\n",
    "    )|rephrase_answer\n",
    ")\n",
    "\n",
    "final_chain.invoke({\"question\":\"\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Few Shots "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adding few shot examples\n",
    "\n",
    "examples = [\n",
    "    {\n",
    "        \"input\":\"How many entries of records are present?\",\n",
    "        \"query\":\"SELECT COUNT(*) from STUDENT;\"\n",
    "    },\n",
    "    {\n",
    "        \"input\":\"Tell me all the students studying  in Data  science class?\",\n",
    "        \"query\":\"SELECT * FROM STUDENT WHERE CLASS='Data Science';\"\n",
    "    },\n",
    "    {\n",
    "        \"input\":\"Tell me number of the students studying in all class?\",\n",
    "        \"query\":\"SELECT count(*) FROM STUDENT;\"\n",
    "    },\n",
    "    {\n",
    "        \"input\":\"Tell me name of the students studying in mba class?\",\n",
    "        \"query\":\"SELECT NAME FROM STUDENT where class='MBA';\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: How many entries of records are present?\n",
      "SQLQuery:\n",
      "AI: SELECT COUNT(*) from STUDENT;\n",
      "Human: Tell me all the students studying  in Data  science class?\n",
      "SQLQuery:\n",
      "AI: SELECT * FROM STUDENT WHERE CLASS='Data Science';\n",
      "Human: Tell me number of the students studying in all class?\n",
      "SQLQuery:\n",
      "AI: SELECT count(*) FROM STUDENT;\n",
      "Human: Tell me name of the students studying in mba class?\n",
      "SQLQuery:\n",
      "AI: SELECT NAME FROM STUDENT where class='MBA';\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,FewShotChatMessagePromptTemplate\n",
    "\n",
    "# Customize Prompt for output\n",
    "\n",
    "from operator import itemgetter\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(\"\"\"\n",
    "Given the following user question, corresponding sql query, and SQL result. Answer from user point of view and avoid mention of SQL query\n",
    "If you don't find the answer ask user to repharse question.\n",
    "Question:{question}\n",
    "SQL_query:{query}\n",
    "SQL_Result:{result}\n",
    "Answer:\n",
    "\"\"\")\n",
    "\n",
    "rephrase_answer = answer_prompt | llm |StrOutputParser()\n",
    "\n",
    "example_prompt = ChatPromptTemplate.from_messages(\n",
    "     [\n",
    "         (\"human\", \"{input}\\nSQLQuery:\"),\n",
    "         (\"ai\", \"{query}\"),\n",
    "     ]\n",
    " )\n",
    "few_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "     example_prompt=example_prompt,\n",
    "     examples=examples,\n",
    "     input_variables=[\"input\",\"top_k\",'table_info']\n",
    " )\n",
    "print(few_shot_prompt.format(input=\"How many students are there?\",top_k = '',table_info = \"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic FewShot selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shambhuraj patil\\AppData\\Local\\Temp\\ipykernel_13316\\792116937.py:7: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vector_store = Chroma()\n",
      "c:\\Users\\shambhuraj patil\\anaconda3\\envs\\llms_env\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "c:\\Users\\shambhuraj patil\\anaconda3\\envs\\llms_env\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Human: Tell me number of the students studying in all class?\n",
      "SQLQuery:\n",
      "AI: SELECT count(*) FROM STUDENT;\n",
      "Human: Tell me name of the students studying in mba class?\n",
      "SQLQuery:\n",
      "AI: SELECT NAME FROM STUDENT where class='MBA';\n"
     ]
    }
   ],
   "source": [
    "### Dynamic Fewshot Example selection\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_core.example_selectors import SemanticSimilarityExampleSelector\n",
    "from langchain_huggingface.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "vector_store = Chroma()\n",
    "vector_store.delete_collection()\n",
    "example_selector = SemanticSimilarityExampleSelector.from_examples(\n",
    "    examples,\n",
    "    HuggingFaceEmbeddings(model_name = \"all-MiniLM-L6-v2\"),\n",
    "    vector_store,\n",
    "    k = 2,\n",
    "    input_keys = ['input'],\n",
    ")\n",
    "\n",
    "example_selector.select_examples({\"input\":\"Tell me name of student with lowest marks across all classes\"})\n",
    "\n",
    "\n",
    "sorted_shot_prompt = FewShotChatMessagePromptTemplate(\n",
    "    example_prompt = example_prompt,\n",
    "    example_selector=example_selector,  ## This line is modified only\n",
    "    input_variables=[\"input\",\"top_k\",'table_info']\n",
    ")\n",
    "print(sorted_shot_prompt.format(input=\"How many students are there?\",top_k = 3,table_info=\"\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The students in the MBA class are Raahish and Grace. \\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "exe_query = QuerySQLDataBaseTool(db=db)\n",
    "final_prompt = ChatPromptTemplate.from_messages(\n",
    "     [\n",
    "         (\"system\", \"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\n\\nHere is the relevant table info: {table_info}\\n\\nBelow are a number of examples of questions and their corresponding SQL queries.\"),\n",
    "        #  few_shot_prompt,\n",
    "        sorted_shot_prompt,\n",
    "         (\"human\", \"OutPut should only Contain SQL query and Nothing else and nothing else associated with it. {input}\"),\n",
    "     ]\n",
    " )\n",
    "\n",
    "generate_query = create_sql_query_chain(llm,db,final_prompt)\n",
    "\n",
    "chain = (\n",
    " RunnablePassthrough.assign(query=generate_query).assign(\n",
    "     result=itemgetter(\"query\") | exe_query\n",
    " )\n",
    " | rephrase_answer\n",
    " )\n",
    "chain.invoke({\"question\": \"Tell me name of students of class MBA\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory to chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain_core.prompts import MessagesPlaceholder\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "\n",
    "memory_prompt = ChatPromptTemplate.from_messages(\n",
    "     [\n",
    "         (\"system\", \"You are a MySQL expert. Given an input question, create a syntactically correct MySQL query to run. Unless otherwise specificed.\\n\\nHere is the relevant table info: {table_info}\\n\\nBelow are a number of examples of questions and their corresponding SQL queries.\"),\n",
    "        #  few_shot_prompt,\n",
    "        sorted_shot_prompt,\n",
    "        MessagesPlaceholder(variable_name='messages'),\n",
    "         (\"human\", \"OutPut should only Contain SQL query and Nothing else and nothing else associated with it. {input}\"),\n",
    "     ]\n",
    " )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_query = create_sql_query_chain(llm,db,memory_prompt)\n",
    "\n",
    "chat_chain = (\n",
    "    RunnablePassthrough.assign(query=generate_query).assign(result=itemgetter(\"query\")|exe_query) |rephrase_answer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 2 students in the MBA class. \\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_chain.invoke({'question':\"tell me number of students from class MBA\",\"messages\":history.messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "history.add_user_message(\"tell me number of students from class MBA\")\n",
    "history.add_ai_message(\"There are 2 students in the MBA class.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The students in the MBA class are Raahish and Grace. \\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_chain.invoke({'question':\"tell me names of those students\",\"messages\":history.messages})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"C:/Users/shambhuraj patil/Desktop/New_career/Git_repos/Genai_project/data/diabetes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
       "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
